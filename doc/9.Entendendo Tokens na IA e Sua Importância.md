## Entendendo Tokens na IA e Sua Importância

### Introdução aos Tokens

Um dos tópicos mais importantes ao usar a API da OpenAI, e ao trabalhar com IA em geral, são os tokens. Os tokens são fundamentais porque são a base para o cálculo de custos pela maioria dos provedores de IA. O número de tokens em nossos prompts determina o modelo que podemos usar e o custo associado a esse uso.

### O Que São Tokens?

Para entender melhor os tokens, podemos usar uma ferramenta fornecida pela OpenAI chamada Tokenizer. Vamos abrir o navegador e procurar por "OpenAI Tokenizer". Neste site, podemos inserir nosso texto e ver como ele é tokenizado.

Por exemplo, ao digitar "How are you today?" e adicionar um ponto de interrogação, o texto será dividido em tokens coloridos. Em geral, os tokens têm aproximadamente quatro caracteres de comprimento, mas isso não é uma regra fixa. Palavras em inglês, como "today", são divididas em tokens.

### Tokenização de Palavras

Se adicionarmos pontuações, como pontos de interrogação adicionais, veremos que eles são agrupados em tokens separados. Por exemplo, "today?" pode ser um token, e "today??" pode ser dois tokens diferentes.

### Algoritmos de Tokenização

Existem dois algoritmos de tokenização importantes: Byte Pair Encoding e WordPiece. Você pode aprender mais sobre eles em tutoriais no site da Hugging Face. Esses algoritmos são cruciais para entender como a tokenização funciona e por que é importante.

### Custo por Tokens

O número de tokens é importante porque determina como a OpenAI e outros provedores de IA cobram pelo uso. Na página de preços da OpenAI, vemos que diferentes modelos têm custos diferentes por 1.000 tokens. O GPT-4 Turbo, por exemplo, é o mais poderoso e tem um custo mais alto. O GPT-3.5, por outro lado, é mais barato e recentemente teve uma redução de preço.

### Contando Tokens em Prompts

Para encontrar o número de tokens em um prompt, podemos usar uma biblioteca externa chamada `tiktoken`. Vamos instalá-la e usá-la para contar tokens em nossos prompts.

#### Passos para Contar Tokens

1. Instalar a biblioteca `tiktoken`:
   ```bash
   npm install tiktoken
   ```

2. Importar e usar a biblioteca em nosso código:
   ```javascript
   import { encoding_for_model } from 'tiktoken';

   function encodePrompt() {
       const prompt = "How are you today?";
       const encoder = encoding_for_model('gpt-3.5-turbo');
       const tokens = encoder.encode(prompt);
       console.log(tokens);
       console.log(`Number of tokens: ${tokens.length}`);
   }

   encodePrompt();
   ```

### Conclusão

Entender os tokens é crucial para gerenciar os custos e a eficiência do uso da API da OpenAI. Na próxima aula, discutiremos outros parâmetros importantes para requisições na OpenAI.

---

### Exemplo de Código para Contar Tokens

Para ilustrar a contagem de tokens em um prompt, aqui está um exemplo de código:

```javascript
import { encoding_for_model } from 'tiktoken';

function encodePrompt() {
    const prompt = "How are you today?";
    const encoder = encoding_for_model('gpt-3.5-turbo');
    const tokens = encoder.encode(prompt);
    console.log(tokens);
    console.log(`Number of tokens: ${tokens.length}`);
}

encodePrompt();
```

### Configuração do Ambiente

Certifique-se de ter sua chave de API configurada no arquivo `.env`:
```
OPENAI_API_KEY=sua_chave_aqui
```

E atualize o script de inicialização no `package.json`:
```json
"scripts": {
  "start": "node -r ts-node/register --env-file=.env src/index.ts"
}
```

Com isso, você estará pronto para executar seu projeto e entender melhor como os tokens influenciam o uso e o custo da API da OpenAI.